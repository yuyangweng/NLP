{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-RNN-8-keras-tokenizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuyangweng/NLP/blob/main/NLP_RNN_8_keras_tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnMzW1dhNQck"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from collections import Counter\n",
        "import re\n",
        " \n",
        "# nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        " \n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv0wP6uIKPw_"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "keras.preprocessing.text.Tokenizer() to transform text to index like \n",
        "\n",
        "(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=max_features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWhN4GmcJSwA",
        "outputId": "8340f08f-6890-4f9b-a4aa-611e51286c4a"
      },
      "source": [
        "text0 = ['this is a book','today is a sunny day']\n",
        "tok = keras.preprocessing.text.Tokenizer()\n",
        "tok.fit_on_texts(text0)\n",
        "print(tok.word_index)\n",
        "print(tok.texts_to_sequences(text0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'is': 1, 'a': 2, 'this': 3, 'book': 4, 'today': 5, 'sunny': 6, 'day': 7}\n",
            "[[3, 1, 2, 4], [5, 1, 2, 6, 7]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gbi7tg4yK3Zg"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Sentiment classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5iKnMfHGsU1",
        "outputId": "697308bc-cea8-4bb8-c97b-6966cf83d402"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyGgny_qGkYU"
      },
      "source": [
        "tweets = pd.read_csv('/content/drive/MyDrive/00NLP/twitter_sentiment.csv', encoding='latin1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l4bh9Q6PZg9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "70a560fa-f67e-4bb6-cd73-613af70dfcf7"
      },
      "source": [
        "tweets.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ItemID</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SentimentText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>is so sad for my APL frie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>I missed the New Moon trail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>omg its already 7:30 :O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ItemID  Sentiment                                      SentimentText\n",
              "0       1          0                       is so sad for my APL frie...\n",
              "1       2          0                     I missed the New Moon trail...\n",
              "2       3          1                            omg its already 7:30 :O\n",
              "3       4          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
              "4       5          0           i think mi bf is cheating on me!!!   ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lagl5YhpQhR3"
      },
      "source": [
        "tweets=tweets.drop(['ItemID'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CDBBSh1RJ3F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "a9225652-52f1-4669-d466-f8e85c436cae"
      },
      "source": [
        "tweets.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SentimentText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>is so sad for my APL frie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>I missed the New Moon trail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>omg its already 7:30 :O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentiment                                      SentimentText\n",
              "0          0                       is so sad for my APL frie...\n",
              "1          0                     I missed the New Moon trail...\n",
              "2          1                            omg its already 7:30 :O\n",
              "3          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
              "4          0           i think mi bf is cheating on me!!!   ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPsj1BqfXazw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0983283f-ce68-4833-8757-175bdb74c50f"
      },
      "source": [
        "target_cnt = Counter(tweets.Sentiment)\n",
        " \n",
        "print(target_cnt.keys(), target_cnt.values())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys([0, 1]) dict_values([43532, 56457])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnbUsbGnXd5Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ec7717-e6ff-48b0-b0fb-4f9e06dc0aab"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words(\"english\")\n",
        "stemmer = SnowballStemmer(\"english\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARIFPosCXoR2"
      },
      "source": [
        "def preprocessor(text):\n",
        "    text = re.sub('<[^>]*>', '', text) # re.sub 取代\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text) # :-) ;-( =-D :-P :D :-(\n",
        "    text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
        "            ' '.join(emoticons).replace('-', ''))\n",
        "    return text\n",
        " \n",
        "def preprocess(text, stem=False):\n",
        "    text = preprocessor(str(text)).strip()\n",
        "    tokens = []\n",
        "    for token in text.split():\n",
        "        if token not in stop_words:\n",
        "            if stem:\n",
        "                tokens.append(stemmer.stem(token))\n",
        "            else:\n",
        "                tokens.append(token)\n",
        "    return \" \".join(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y18C6WvfYm4s"
      },
      "source": [
        "tweets.SentimentText = tweets.SentimentText.apply(lambda x: preprocess(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "F_qFkqqFI4UE",
        "outputId": "6bcb4f17-10a3-42ae-abc6-2c493bb3f116"
      },
      "source": [
        "tweets.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SentimentText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>sad apl friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>missed new moon trailer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>omg already 7 30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>omgaga im sooo im gunna cry dentist since 11 s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>think mi bf cheating t_t</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentiment                                      SentimentText\n",
              "0          0                                     sad apl friend\n",
              "1          0                            missed new moon trailer\n",
              "2          1                                   omg already 7 30\n",
              "3          0  omgaga im sooo im gunna cry dentist since 11 s...\n",
              "4          0                           think mi bf cheating t_t"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6kHwVFNZYJP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ece9cb-dd5a-460f-c753-25581e29cf51"
      },
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(tweets.SentimentText)\n",
        " \n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"Total words\", vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total words 103102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5L7QqlnyUAg"
      },
      "source": [
        "df = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y-if17_otSp"
      },
      "source": [
        "df['SentimentText'] = tokenizer.texts_to_sequences(tweets.SentimentText)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_2vA6u4yqaQ"
      },
      "source": [
        "df['Sentiment'] = tweets['Sentiment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "SXqrsfWQRvU5",
        "outputId": "b01879d1-1d3d-4d56-c23c-7ee758b55b8c"
      },
      "source": [
        "df[-10:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SentimentText</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>99979</th>\n",
              "      <td>[103094, 313, 11, 62, 313, 458, 87]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99980</th>\n",
              "      <td>[103095, 654, 2785, 1005, 87]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99981</th>\n",
              "      <td>[1086, 398, 716, 1846, 23, 58, 3, 692, 138, 14...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99982</th>\n",
              "      <td>[1086, 3509, 5068, 48, 1722, 14, 6670, 1847, 9...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99983</th>\n",
              "      <td>[103097, 421, 6580, 115, 5, 476, 3815, 40, 23,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99984</th>\n",
              "      <td>[2644, 331, 3, 6789, 356, 25, 312, 105, 94]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99985</th>\n",
              "      <td>[2644, 103098, 1238, 611, 256, 17, 13, 10298, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99986</th>\n",
              "      <td>[2644, 103100, 97, 107]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99987</th>\n",
              "      <td>[2644, 103101, 41, 41, 103, 48]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99988</th>\n",
              "      <td>[2644, 7707, 22, 41]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           SentimentText  Sentiment\n",
              "99979                [103094, 313, 11, 62, 313, 458, 87]          1\n",
              "99980                      [103095, 654, 2785, 1005, 87]          1\n",
              "99981  [1086, 398, 716, 1846, 23, 58, 3, 692, 138, 14...          0\n",
              "99982  [1086, 3509, 5068, 48, 1722, 14, 6670, 1847, 9...          1\n",
              "99983  [103097, 421, 6580, 115, 5, 476, 3815, 40, 23,...          0\n",
              "99984        [2644, 331, 3, 6789, 356, 25, 312, 105, 94]          0\n",
              "99985  [2644, 103098, 1238, 611, 256, 17, 13, 10298, ...          1\n",
              "99986                            [2644, 103100, 97, 107]          0\n",
              "99987                    [2644, 103101, 41, 41, 103, 48]          1\n",
              "99988                               [2644, 7707, 22, 41]          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30FZDm5kYo3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6b9b001-5aad-4a46-bb4b-b6d2b2de63c8"
      },
      "source": [
        "df_train, df_test = train_test_split(df, test_size=0.1, random_state=1)\n",
        "print(\"TRAIN size:\", len(df_train))\n",
        "print(\"TEST size:\", len(df_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN size: 89990\n",
            "TEST size: 9999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHnVVmwUZq9J"
      },
      "source": [
        "x_train = keras.preprocessing.sequence.pad_sequences(df_train.SentimentText.values, maxlen=300)\n",
        "x_test = keras.preprocessing.sequence.pad_sequences(df_test.SentimentText.values, maxlen=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKFyfJzQvQR9",
        "outputId": "aeac62c2-7cc0-49f6-a481-4d1a77001c14"
      },
      "source": [
        "x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,  450, 3315,  256],\n",
              "       [   0,    0,    0, ...,  162,    8,  895],\n",
              "       [   0,    0,    0, ...,   50,  215,   76],\n",
              "       ...,\n",
              "       [   0,    0,    0, ..., 4062,  391, 2484],\n",
              "       [   0,    0,    0, ...,  369,   79,   91],\n",
              "       [   0,    0,    0, ...,   14,  408, 9405]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbXgQL4XaNDe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fcf6bbd-d669-4f28-9ffc-116121cd9a95"
      },
      "source": [
        "y_train = df_train.Sentiment.values.reshape(-1,1)\n",
        "y_test = df_test.Sentiment.values.reshape(-1,1)\n",
        "\n",
        "print(\"y_train\",y_train.shape)\n",
        "print(\"y_test\",y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train (89990, 1)\n",
            "y_test (9999, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgLo6ygcvzQZ",
        "outputId": "3a6dfd10-e227-41a4-872b-98f15f494326"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0],\n",
              "       [0],\n",
              "       ...,\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1CLnex8Lpa4"
      },
      "source": [
        "max_features = vocab_size  # 要考慮作為特徵的語詞數量\n",
        "maxlen = 300  # 當句子的長度超過300個語詞的部份,就把它刪除掉\n",
        "batch_size = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At0pJDKqJF1G",
        "outputId": "7012e912-c83b-419e-9e67-14a2a37634ff"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding\n",
        "\n",
        "model = Sequential()   # 輸入 （sample size，time steps） with label encoding              \n",
        "model.add(Embedding(max_features, 4, input_length=maxlen)) # => 參數(input features, output features, time steps)\n",
        "model.add(Dropout(0.5)) # 承接 embedding 輸出 （sample size，time steps, output features） \n",
        "model.add(LSTM(8, return_sequences=True)) # 輸入 （sample size，time steps, input features） \n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(4))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=4,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 300, 4)            412408    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 300, 4)            0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 300, 8)            416       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 300, 8)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 4)                 208       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 413,037\n",
            "Trainable params: 413,037\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/4\n",
            "4500/4500 [==============================] - 99s 21ms/step - loss: 0.6134 - binary_accuracy: 0.6642 - val_loss: 0.5339 - val_binary_accuracy: 0.7375\n",
            "Epoch 2/4\n",
            "4500/4500 [==============================] - 93s 21ms/step - loss: 0.5301 - binary_accuracy: 0.7470 - val_loss: 0.5152 - val_binary_accuracy: 0.7473\n",
            "Epoch 3/4\n",
            "4500/4500 [==============================] - 94s 21ms/step - loss: 0.4806 - binary_accuracy: 0.7827 - val_loss: 0.5215 - val_binary_accuracy: 0.7449\n",
            "Epoch 4/4\n",
            "4500/4500 [==============================] - 95s 21ms/step - loss: 0.4424 - binary_accuracy: 0.8068 - val_loss: 0.5369 - val_binary_accuracy: 0.7330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AReX0GTTJFye",
        "outputId": "b3f8b00b-aabf-4dfb-d279-d83c5dfe18ae"
      },
      "source": [
        "model.evaluate(x_test, y_test, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 5s 8ms/step - loss: 0.5364 - binary_accuracy: 0.7323\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5364326238632202, 0.7322732210159302]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkktB_1gQT73"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "加入 word2vec 預訓練 embedding weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RPW3cZsJFvV"
      },
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "gensim_model = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/00NLP/GoogleNews-vectors-negative300.bin.gz', binary=True, limit=300000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYE903MlUbkK",
        "outputId": "042eac41-cdf0-42a1-984d-69bb255c3164"
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(tweets.SentimentText)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"Total words\", vocab_size)\n",
        "print([word for word, index in tokenizer.word_index.items()][:100])\n",
        "print([index for word, index in tokenizer.word_index.items()][:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total words 103102\n",
            "['quot', 'good', 'like', 'lol', 'get', 'u', 'know', 'love', 'thanks', 'one', 'go', 'day', 'see', 'amp', 'well', 'http', 'time', 'got', 'im', 'oh', 'think', 'haha', 'really', 'going', 'hope', 'work', 'sorry', 'back', 'still', 'yeah', 'com', 'would', 'want', 'today', 'much', '2', 'great', 'miss', 'need', 'right', 'yes', 'new', 'twitter', '3', 'night', 'though', 'come', 'fun', 'hey', 'make', 'last', 'better', 'thank', 'sad', 'wish', 'feel', 'nice', 'bad', 'lt', 'could', 'way', 'home', 'happy', 'morning', 'awesome', 'never', 'ur', 'sure', 'bit', 'say', 'even', 'always', 'dont', 'people', 'wait', 'us', 'ok', 'soon', 'take', 'tomorrow', 'week', 'next', 'let', 'gonna', 'cool', 'show', 'x', 'please', 'thing', 'follow', 'look', '4', 'guys', 'something', 'tonight', 'twitpic', 'ya', 'getting', 'hear', 'tell']\n",
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttPFyMlAJFsU",
        "outputId": "94045ffd-270f-41e2-b1a1-47fd97e1c5ae"
      },
      "source": [
        "embedding_weights = np.zeros((vocab_size, maxlen))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    try:\n",
        "      embedding_weights[index, :] = gensim_model.wv[word]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGgXPZsGJFmy",
        "outputId": "d103b39f-9b93-4912-c29b-d2ca013ecf80"
      },
      "source": [
        "embedding_weights.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(103102, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPGO4nmcJFjy"
      },
      "source": [
        "max_features = vocab_size  # 要考慮作為特徵的語詞數量\n",
        "maxlen = 300  # 當句子的長度超過300個語詞的部份,就把它刪除掉\n",
        "batch_size = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB5PqgyBJFg8",
        "outputId": "03fc2db9-79bc-47ce-c564-b8fa9a22ab3d"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding\n",
        "\n",
        "model = Sequential()   # 輸入 （sample size，time steps） with label encoding              \n",
        "model.add(Embedding(max_features, embedding_weights.shape[1], input_length=maxlen, weights = [embedding_weights])) # => 參數 weights = [embedding_weights]\n",
        "model.add(Dropout(0.5)) # 承接 embedding 輸出 （sample size，time steps, output features） \n",
        "model.add(LSTM(8, return_sequences=True)) # 輸入 （sample size，time steps, input features） \n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(4))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=1,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 300, 300)          30930600  \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 300, 300)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 300, 8)            9888      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 300, 8)            0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 4)                 208       \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 30,940,701\n",
            "Trainable params: 30,940,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "4500/4500 [==============================] - 791s 175ms/step - loss: 0.5782 - binary_accuracy: 0.7044 - val_loss: 0.5048 - val_binary_accuracy: 0.7523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8zjClpYJFd-",
        "outputId": "d9f7239c-8490-4c34-b0c3-cd0e66389fce"
      },
      "source": [
        "model.evaluate(x_test, y_test, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 6s 10ms/step - loss: 0.5069 - binary_accuracy: 0.7533\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5069248080253601, 0.7532753348350525]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lsz0PIufyla"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "callbacks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgSYft_Cf2s-"
      },
      "source": [
        "checkpoint = keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/00NLP/tok.h5', monitor='val_accuracy', mode=\"max\", save_best_only=True, verbose=1)\n",
        "earlystopping = keras.callbacks.EarlyStopping(monitor='val_accuracy', mode=\"max\", patience=5, verbose=1)\n",
        "rlr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, mode='auto', min_delta=0.0001)\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=16,\n",
        "     validation_split=0.2, callbacks=[checkpoint,earlystopping,rlr])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}